{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from model import ImageCNN,MatchCNN\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from data_loader import get_loader,CocoDataset\n",
    "from build_vocab import Vocabulary\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.58s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"load coco dataset\"\"\"\n",
    "data_dir = \"../data/coco/\"\n",
    "annotation_file = data_dir + \"annotations/captions_train2014.json\"\n",
    "coco=COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# anns = coco.anns\n",
    "# imgs = coco.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"extract 100 imgid and corresponding 500 captionid\"\"\"\n",
    "sample_num = 100\n",
    "caption_num = sample_num * 5\n",
    "img_ids_all = list(coco.imgs.keys())\n",
    "shuffle(img_ids_all)\n",
    "img_ids = []\n",
    "ann_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in img_ids_all:\n",
    "    temp = coco.getAnnIds(key)\n",
    "    if(len(temp) != 5):\n",
    "        continue\n",
    "    ann_ids.append(temp)\n",
    "    img_ids.append(key)\n",
    "    if(len(img_ids) == sample_num):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"preprocess images\"\"\"\n",
    "image_dir = data_dir + \"resized2014/\"\n",
    "imgs = []\n",
    "\n",
    " # Image preprocessing\n",
    "transform = transforms.Compose([ \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "for i, img_id in enumerate(img_ids):\n",
    "    img_new = {}\n",
    "    img = coco.imgs[img_id]\n",
    "    image = Image.open(image_dir + img[\"file_name\"]).convert(\"RGB\")\n",
    "    image = transform(image)\n",
    "    img_new[\"ann_ids\"] = ann_ids[i]\n",
    "    img_new[\"data\"] = image\n",
    "    img_new[\"id\"] = img_id\n",
    "    imgs.append(img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"preprocess annotations\"\"\"\n",
    "vocab_file = \"../data/coco/vocab.pkl\"\n",
    "pad_len = 62\n",
    "# Load vocabulary wrapper.\n",
    "with open(vocab_file, 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "anns = np.zeros((caption_num, pad_len),dtype = int)\n",
    "for i,ann_ids_image in enumerate(ann_ids):\n",
    "    for j,ann_id in enumerate(ann_ids_image):\n",
    "        caption_str = coco.anns[ann_id][\"caption\"]\n",
    "        tokens = nltk.tokenize.word_tokenize(str(caption_str).lower())\n",
    "        caption = []\n",
    "        caption.append(vocab('<start>'))\n",
    "        caption.extend([vocab(token) for token in tokens])\n",
    "        caption.append(vocab('<end>'))\n",
    "        caption = np.array(caption)\n",
    "        anns[i*5 + j][:len(tokens) + 2] = caption[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatchCNN (\n",
       "  (embed): Embedding(9956, 100)\n",
       "  (muti_conv1_word): Linear (556 -> 200)\n",
       "  (conv2_word): Linear (600 -> 300)\n",
       "  (conv3_word): Linear (900 -> 300)\n",
       "  (linear1_word): Linear (1800 -> 400)\n",
       "  (linear2_word): Linear (400 -> 1)\n",
       "  (conv1_phs): Linear (300 -> 200)\n",
       "  (muti_conv2_phs): Linear (856 -> 300)\n",
       "  (conv3_phs): Linear (900 -> 300)\n",
       "  (linear1_phs): Linear (1800 -> 400)\n",
       "  (linear2_phs): Linear (400 -> 1)\n",
       "  (conv1_phl): Linear (300 -> 200)\n",
       "  (conv2_phl): Linear (600 -> 300)\n",
       "  (muti_conv3_phl): Linear (1156 -> 300)\n",
       "  (linear1_phl): Linear (1800 -> 400)\n",
       "  (linear2_phl): Linear (400 -> 1)\n",
       "  (conv1_sen): Linear (300 -> 200)\n",
       "  (conv2_sen): Linear (600 -> 300)\n",
       "  (conv3_sen): Linear (900 -> 300)\n",
       "  (muti_linear1_sen): Linear (2056 -> 400)\n",
       "  (linear2_sen): Linear (400 -> 1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"parameters\"\"\"\n",
    "image_vector_size = 256\n",
    "embed_size = 100\n",
    "margin = 0.5\n",
    "batch_size = 10\n",
    "epochs = 1\n",
    "vocab_size = 9956\n",
    "momentum=0.9\n",
    "lr = 0.0001\n",
    "pad_len = 62\n",
    "num_workers = 2\n",
    "batch_size = 100\n",
    "\n",
    "\"\"\"set model\"\"\"\n",
    "imageCNN = ImageCNN(image_vector_size=image_vector_size)\n",
    "matchCNN = MatchCNN(embed_size = embed_size, \n",
    "                    image_vector_size = image_vector_size, \n",
    "                    vocab_size = vocab_size, \n",
    "                    pad_len = pad_len)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available\")\n",
    "    imageCNN = imageCNN.cuda()\n",
    "    matchCNN = matchCNN.cuda()\n",
    "\n",
    "imageCNN.eval()\n",
    "matchCNN.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load models\"\"\"\n",
    "model_path = \"../models\"\n",
    "imageCNN.load_state_dict(torch.load(os.path.join(model_path, 'imageCNN1513584698-2-0.099086.pkl')))\n",
    "matchCNN.load_state_dict(torch.load(os.path.join(model_path, 'matchCNN1513584698-2-0.099086.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"extract image feature\"\"\"\n",
    "img_features = torch.zeros((sample_num, image_vector_size))\n",
    "img_input = torch.zeros((batch_size, 3, 224, 224))\n",
    "for i, img in enumerate(imgs):\n",
    "    img_input[i%batch_size] = img[\"data\"]\n",
    "    if((i+1)%batch_size == 0):\n",
    "        img_features[i+1-batch_size:i+1] = imageCNN(Variable(img_input).cuda()).data[:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = torch.zeros((sample_num, sample_num*5))\n",
    "for i,img in enumerate(img_features):\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.repeat(batch_size,1)\n",
    "    img = Variable(img).cuda()\n",
    "    for j in range(int(caption_num/batch_size)):\n",
    "        ann_input = Variable(torch.from_numpy(anns[j*batch_size:(j+1)*batch_size])).cuda()\n",
    "\n",
    "        scores[i][j*batch_size:(j+1)*batch_size] = matchCNN(img, ann_input).data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " -4.3912\n",
       " -8.0284\n",
       " -4.1740\n",
       " -5.6836\n",
       " -5.5024\n",
       " -3.4043\n",
       " -3.3955\n",
       " -4.0552\n",
       " -3.2483\n",
       " -3.3294\n",
       " -6.0023\n",
       " -4.3673\n",
       " -4.8983\n",
       " -5.9815\n",
       " -4.6593\n",
       " -3.5766\n",
       " -2.9850\n",
       " -3.7978\n",
       " -3.3847\n",
       " -3.0843\n",
       " -5.6165\n",
       " -7.9343\n",
       " -7.3320\n",
       " -7.3406\n",
       " -4.5620\n",
       " -4.7784\n",
       " -3.5087\n",
       " -3.6286\n",
       " -4.9043\n",
       " -3.7532\n",
       "-10.8512\n",
       "-10.7423\n",
       " -9.6521\n",
       " -8.3601\n",
       " -5.6349\n",
       " -3.9638\n",
       " -3.9641\n",
       " -2.9482\n",
       " -4.3373\n",
       " -2.5172\n",
       " -3.0222\n",
       " -3.9355\n",
       " -5.1903\n",
       " -5.8846\n",
       " -5.2306\n",
       " -5.0450\n",
       " -4.9086\n",
       " -3.7830\n",
       " -4.2595\n",
       " -4.8241\n",
       " -5.4933\n",
       " -4.1694\n",
       " -2.5362\n",
       " -4.2888\n",
       " -5.0269\n",
       " -4.4679\n",
       " -6.6931\n",
       " -5.9393\n",
       " -4.6897\n",
       " -5.0898\n",
       " -8.1498\n",
       " -5.5907\n",
       " -7.2148\n",
       " -6.2689\n",
       " -4.6996\n",
       " -2.9625\n",
       " -3.8484\n",
       " -3.9312\n",
       " -5.8361\n",
       " -5.9312\n",
       " -3.4390\n",
       " -4.0774\n",
       " -3.8916\n",
       " -4.3954\n",
       " -3.8559\n",
       " -5.9995\n",
       " -2.8812\n",
       " -7.2780\n",
       " -5.4364\n",
       " -4.7646\n",
       " -4.9933\n",
       " -4.8139\n",
       " -4.5694\n",
       " -5.8373\n",
       " -4.9829\n",
       " -3.5730\n",
       " -3.0351\n",
       " -2.7821\n",
       " -6.0184\n",
       " -3.2136\n",
       " -4.5833\n",
       " -4.3143\n",
       " -3.7560\n",
       " -4.4999\n",
       " -5.5077\n",
       " -5.1256\n",
       " -4.9243\n",
       " -5.1443\n",
       " -4.2053\n",
       " -4.1429\n",
       " -9.1681\n",
       " -6.8289\n",
       " -8.8536\n",
       " -7.3052\n",
       " -6.2879\n",
       " -3.4121\n",
       " -4.6529\n",
       " -6.1512\n",
       " -6.8170\n",
       " -6.7554\n",
       " -8.6813\n",
       " -7.1798\n",
       " -8.7290\n",
       " -4.9776\n",
       " -5.4224\n",
       " -4.9524\n",
       " -4.4789\n",
       " -3.9082\n",
       " -4.8923\n",
       " -3.7026\n",
       " -5.0968\n",
       " -5.0201\n",
       " -5.6678\n",
       " -4.3691\n",
       " -3.7321\n",
       " -5.0959\n",
       " -5.3855\n",
       " -5.4434\n",
       " -4.9112\n",
       " -4.8893\n",
       " -4.4327\n",
       " -3.8289\n",
       " -2.9522\n",
       " -3.4595\n",
       " -3.5546\n",
       " -3.8028\n",
       " -2.1022\n",
       " -2.5748\n",
       " -5.1028\n",
       " -4.0368\n",
       " -3.8524\n",
       " -3.8996\n",
       " -6.0876\n",
       " -2.7588\n",
       " -5.0167\n",
       " -5.7849\n",
       " -4.8443\n",
       " -4.7381\n",
       " -6.4522\n",
       " -5.1286\n",
       " -5.5681\n",
       " -4.6810\n",
       " -5.2648\n",
       " -5.4189\n",
       " -5.1101\n",
       " -4.6771\n",
       " -4.3376\n",
       " -3.8385\n",
       " -3.6646\n",
       " -3.2510\n",
       " -5.9236\n",
       " -5.7572\n",
       " -4.7804\n",
       " -5.1312\n",
       " -6.0671\n",
       " -5.8101\n",
       " -3.8983\n",
       " -5.8024\n",
       " -3.8689\n",
       " -5.0513\n",
       " -3.5589\n",
       " -3.4632\n",
       " -3.4198\n",
       " -2.9232\n",
       " -4.9160\n",
       " -2.0487\n",
       " -2.7080\n",
       " -2.6322\n",
       " -2.3832\n",
       " -2.6608\n",
       " -6.5287\n",
       " -7.5530\n",
       " -6.4461\n",
       " -9.2937\n",
       " -7.7339\n",
       " -3.8286\n",
       " -7.0135\n",
       "-10.1248\n",
       " -9.2618\n",
       " -8.0237\n",
       " -8.0778\n",
       " -9.2100\n",
       " -7.7374\n",
       " -9.2458\n",
       " -8.4593\n",
       " -9.7876\n",
       "-10.7180\n",
       "-11.0392\n",
       "-10.0335\n",
       " -7.3316\n",
       " -4.6650\n",
       " -4.9368\n",
       " -3.1912\n",
       " -3.5319\n",
       " -7.4609\n",
       " -4.1227\n",
       " -5.2831\n",
       " -4.4928\n",
       " -3.7115\n",
       " -4.7410\n",
       " -4.2305\n",
       " -4.5517\n",
       " -3.9429\n",
       " -4.6154\n",
       " -5.1755\n",
       " -3.7112\n",
       " -3.4811\n",
       " -2.8287\n",
       " -5.3916\n",
       " -5.2187\n",
       " -4.2417\n",
       " -4.6339\n",
       " -3.5870\n",
       " -4.8575\n",
       " -4.8334\n",
       " -7.8416\n",
       " -8.5767\n",
       " -8.6158\n",
       " -6.6214\n",
       " -7.6295\n",
       " -3.9993\n",
       " -3.5609\n",
       " -2.9650\n",
       " -2.9607\n",
       " -2.6765\n",
       " -5.8968\n",
       " -5.8888\n",
       " -6.0401\n",
       " -5.1036\n",
       " -6.2583\n",
       " -5.1419\n",
       " -4.1911\n",
       " -5.1666\n",
       " -6.3152\n",
       " -5.6546\n",
       " -5.0549\n",
       " -5.3855\n",
       " -5.1441\n",
       " -4.8023\n",
       " -4.6617\n",
       " -6.9500\n",
       " -6.7123\n",
       " -5.8622\n",
       " -7.4199\n",
       " -7.6853\n",
       " -2.9297\n",
       " -4.1534\n",
       " -4.2697\n",
       " -3.7489\n",
       " -4.0371\n",
       " -4.9460\n",
       " -4.0999\n",
       " -4.0077\n",
       " -5.7007\n",
       " -4.5740\n",
       " -5.3979\n",
       " -6.2880\n",
       " -7.9395\n",
       " -5.4428\n",
       " -5.3376\n",
       " -6.6025\n",
       " -5.9035\n",
       " -4.6695\n",
       " -5.0085\n",
       " -5.8524\n",
       " -4.7687\n",
       " -5.7300\n",
       " -4.6726\n",
       " -6.4138\n",
       " -6.4802\n",
       " -5.0085\n",
       " -4.2784\n",
       " -4.0897\n",
       " -4.2898\n",
       " -4.4871\n",
       " -5.2046\n",
       " -2.6492\n",
       " -5.4851\n",
       " -4.8697\n",
       " -2.2273\n",
       " -5.5985\n",
       " -5.4126\n",
       " -5.8273\n",
       " -6.8663\n",
       " -4.9498\n",
       " -2.5073\n",
       " -2.0385\n",
       " -2.6319\n",
       " -2.7924\n",
       " -2.3618\n",
       " -7.5103\n",
       " -7.8100\n",
       " -7.0286\n",
       " -7.0569\n",
       " -6.8953\n",
       " -6.9823\n",
       " -5.0356\n",
       " -6.3175\n",
       " -6.2985\n",
       " -5.7543\n",
       " -4.9705\n",
       " -5.6350\n",
       " -5.0594\n",
       " -4.0629\n",
       " -4.8429\n",
       " -7.8648\n",
       " -6.6014\n",
       " -7.1667\n",
       " -6.5815\n",
       " -9.7676\n",
       " -5.1472\n",
       " -4.7442\n",
       " -6.4192\n",
       " -4.4157\n",
       " -7.3613\n",
       " -4.8087\n",
       " -7.4628\n",
       " -5.5014\n",
       " -5.2294\n",
       " -5.7479\n",
       " -5.2496\n",
       " -5.3687\n",
       " -4.8040\n",
       " -3.0938\n",
       " -4.1576\n",
       " -3.4424\n",
       " -3.5841\n",
       " -3.4631\n",
       " -2.8994\n",
       " -3.2558\n",
       " -6.9568\n",
       " -6.2749\n",
       " -5.9225\n",
       " -6.0768\n",
       " -5.2209\n",
       " -5.1502\n",
       " -2.7795\n",
       " -4.6833\n",
       " -3.8954\n",
       " -4.7675\n",
       " -5.9289\n",
       " -6.1968\n",
       " -5.5000\n",
       " -4.6429\n",
       " -5.6299\n",
       " -5.2911\n",
       " -6.2711\n",
       " -6.3527\n",
       " -5.3715\n",
       " -5.3256\n",
       " -3.7122\n",
       " -2.6715\n",
       " -3.7708\n",
       " -3.3320\n",
       " -2.4293\n",
       " -5.4104\n",
       " -5.6613\n",
       " -5.8503\n",
       " -3.6024\n",
       " -4.1723\n",
       " -6.2581\n",
       " -4.0910\n",
       " -4.2136\n",
       " -3.1190\n",
       " -5.4334\n",
       " -4.9103\n",
       " -4.8660\n",
       " -6.6733\n",
       " -5.3491\n",
       " -4.9439\n",
       " -5.4183\n",
       " -5.1928\n",
       " -4.8147\n",
       " -4.0931\n",
       " -4.7817\n",
       " -4.8317\n",
       " -2.8599\n",
       " -2.9020\n",
       " -4.5700\n",
       " -3.7646\n",
       " -6.3067\n",
       " -5.4148\n",
       " -7.8991\n",
       " -6.1409\n",
       " -4.4617\n",
       " -4.5517\n",
       " -5.2715\n",
       " -5.8109\n",
       " -2.8764\n",
       " -4.2874\n",
       " -6.3128\n",
       " -5.3111\n",
       " -5.5244\n",
       " -6.0475\n",
       " -6.2702\n",
       " -7.0679\n",
       " -4.8353\n",
       " -5.6779\n",
       " -5.6482\n",
       " -7.7332\n",
       " -8.7707\n",
       " -8.0228\n",
       " -8.9612\n",
       " -7.7877\n",
       " -7.7047\n",
       " -5.8247\n",
       " -7.5518\n",
       " -6.9778\n",
       " -8.6840\n",
       " -9.1092\n",
       " -4.2917\n",
       " -4.2558\n",
       " -5.4681\n",
       " -4.9782\n",
       " -4.9116\n",
       " -5.2322\n",
       " -5.1393\n",
       " -3.4265\n",
       " -8.0613\n",
       " -5.4489\n",
       " -7.0068\n",
       " -9.1353\n",
       " -6.4538\n",
       " -6.8196\n",
       " -6.1498\n",
       " -4.7671\n",
       " -5.7320\n",
       " -6.6802\n",
       " -7.3405\n",
       " -6.8867\n",
       " -4.8545\n",
       " -5.7001\n",
       " -5.4046\n",
       " -5.4727\n",
       " -5.3824\n",
       " -4.6800\n",
       " -5.2989\n",
       " -2.8553\n",
       " -7.1317\n",
       " -6.5623\n",
       " -5.0540\n",
       " -4.6084\n",
       " -4.3798\n",
       " -4.0111\n",
       " -4.7922\n",
       " -5.9882\n",
       " -6.4351\n",
       " -6.7565\n",
       " -6.4351\n",
       " -6.3992\n",
       " -6.0690\n",
       " -4.3967\n",
       " -4.2687\n",
       " -4.3220\n",
       " -4.4899\n",
       "-13.3465\n",
       " -8.9741\n",
       " -5.4628\n",
       " -8.7162\n",
       " -7.9307\n",
       " -6.4926\n",
       " -6.6754\n",
       " -5.6435\n",
       " -5.0697\n",
       " -5.3279\n",
       " -5.8382\n",
       " -5.2991\n",
       " -5.0159\n",
       " -6.0663\n",
       " -3.9717\n",
       " -4.6502\n",
       " -5.2936\n",
       " -6.7380\n",
       " -7.1261\n",
       " -5.9473\n",
       " -6.1939\n",
       " -6.0810\n",
       " -6.2160\n",
       " -5.7895\n",
       " -5.6760\n",
       " -5.0960\n",
       " -6.1290\n",
       " -5.6083\n",
       " -5.9473\n",
       " -5.8311\n",
       " -5.2449\n",
       " -5.6779\n",
       " -4.3234\n",
       " -4.9570\n",
       " -5.2760\n",
       "[torch.FloatTensor of size 500]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[465,  30, 187, ..., 364, 136,  37],\n",
       "       [465, 197,  30, ..., 136, 175, 296],\n",
       "       [465, 187,  30, ..., 312, 353, 136],\n",
       "       ..., \n",
       "       [187, 319, 465, ...,  84, 139, 398],\n",
       "       [465, 187, 197, ...,  26, 494, 163],\n",
       "       [465, 187, 188, ...,  98, 179, 136]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_np = scores.numpy()\n",
    "\n",
    "ranks = np.argsort(score_np)\n",
    "\n",
    "ranks_image = np.zeros((sample_num,5),dtype=int)\n",
    "\n",
    "for i in range(sample_num):\n",
    "    ranks_image[i][:] = ranks[i][i*5:(i+1)*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1: 0.0\n",
      "r5: 1.2\n",
      "r10: 1.7999999999999998\n",
      "med: 242.772\n"
     ]
    }
   ],
   "source": [
    "r1 = len(ranks_image[ranks_image==1])/caption_num * 100\n",
    "r5 = len(ranks_image[ranks_image<=5])/caption_num * 100\n",
    "r10 = len(ranks_image[ranks_image<=10])/caption_num * 100\n",
    "med = np.mean(ranks_image)\n",
    "\n",
    "print(\"r1:\",r1)\n",
    "print(\"r5:\",r5)\n",
    "print(\"r10:\",r10)\n",
    "print(\"med:\",med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
